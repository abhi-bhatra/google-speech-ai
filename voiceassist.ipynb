{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffd53d0d-e30a-4734-bb5a-92871c58f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import io\n",
    "import queue\n",
    "import re\n",
    "import sys\n",
    "from google.cloud import speech, texttospeech\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75d72a98-9370-4636-a54e-8f9c050054e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1afc8363-32fb-4659-b918-1d1c0bb14f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self: object, rate: int = RATE, chunk: int = CHUNK) -> None:\n",
    "        \"\"\"The audio -- and generator -- is guaranteed to be on the main thread.\"\"\"\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self: object) -> object:\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(\n",
    "        self: object,\n",
    "        type: object,\n",
    "        value: object,\n",
    "        traceback: object,\n",
    "    ) -> None:\n",
    "        \"\"\"Closes the stream, regardless of whether the connection was lost or not.\"\"\"\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(\n",
    "        self: object,\n",
    "        in_data: object,\n",
    "        frame_count: int,\n",
    "        time_info: object,\n",
    "        status_flags: object,\n",
    "    ) -> object:\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\n",
    "\n",
    "        Args:\n",
    "            in_data: The audio data as a bytes object\n",
    "            frame_count: The number of frames captured\n",
    "            time_info: The time information\n",
    "            status_flags: The status flags\n",
    "\n",
    "        Returns:\n",
    "            The audio data as a bytes object\n",
    "        \"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self: object) -> object:\n",
    "        \"\"\"Generates audio chunks from the stream of audio data in chunks.\n",
    "\n",
    "        Args:\n",
    "            self: The MicrophoneStream object\n",
    "\n",
    "        Returns:\n",
    "            A generator that outputs audio chunks.\n",
    "        \"\"\"\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "879e460f-f9e2-431c-aa69-710a46cababc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speechtotext(responses: object) -> str:\n",
    "    \"\"\"Iterates through server responses and returns the full transcript.\"\"\"\n",
    "    num_chars_printed = 0\n",
    "    full_transcript = \"\"\n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "        \n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "        \n",
    "        transcript = result.alternatives[0].transcript\n",
    "        \n",
    "        overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "        \n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "            num_chars_printed = len(transcript)\n",
    "        else:\n",
    "            full_transcript += transcript + \" \"\n",
    "            num_chars_printed = 0\n",
    "        \n",
    "        if re.search(r\"\\b(बस|bye|exit)\\b\", transcript, re.I):\n",
    "            print(\"Goodbye command recognized. Stopping...\")\n",
    "            return full_transcript.strip()\n",
    "    \n",
    "    return full_transcript.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5c2a528-4991-4676-915a-d041e9aa6e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"Transcribe speech from audio file.\"\"\"\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    language_code = \"hi-IN\"  # a BCP-47 language tag\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code,\n",
    "        model=\"command_and_search\",\n",
    "        use_enhanced=True,\n",
    "        enable_automatic_punctuation=True,\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content)\n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        # Get the transcribed text\n",
    "        transcribed_text = speechtotext(responses)\n",
    "        \n",
    "        print(\"Speech to Text Response:\", transcribed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac5f6812-062a-475e-ab5a-0175b4602165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye command recognized. Stopping...\n",
      "Speech to Text Response: मुझे गूगल जीमेल की जानकारी चाहिए।\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cffb48b-cb78-4fc8-8f3d-7b7fe61f7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech_stream(text: str) -> None:\n",
    "    \"\"\"\n",
    "    Converts plaintext to SSML, generates synthetic audio from SSML,\n",
    "    and plays it directly through the speakers.\n",
    "\n",
    "    Args:\n",
    "    text (str): text to synthesize and play\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Replace special characters with HTML Ampersand Character Codes\n",
    "    escaped_lines = html.escape(text)\n",
    "\n",
    "    # Convert plaintext to SSML\n",
    "    ssml = \"<speak>{}</speak>\".format(\n",
    "        escaped_lines.replace(\"\\n\", '\\n<break time=\"1s\"/>')\n",
    "    )\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    # Sets the text input to be synthesized\n",
    "    synthesis_input = texttospeech.SynthesisInput(ssml=ssml)\n",
    "\n",
    "    # Builds the voice request\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"hi-IN\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "    )\n",
    "\n",
    "    # Selects the type of audio file\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.LINEAR16\n",
    "    )\n",
    "\n",
    "    # Performs the text-to-speech request\n",
    "    response = client.synthesize_speech(\n",
    "        input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    # Play the audio\n",
    "    audio_data = io.BytesIO(response.audio_content)\n",
    "    \n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=p.get_format_from_width(2),  # 16-bit\n",
    "                    channels=1,\n",
    "                    rate=24000,\n",
    "                    output=True)\n",
    "\n",
    "    chunk = 1024\n",
    "    data = audio_data.read(chunk)\n",
    "\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = audio_data.read(chunk)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    print(\"Audio playback completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adcb3124-892c-4f8d-bdc5-14726113b9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio playback completed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_text = \"नमस्ते, मैं आपका डिजिटल दोस्त हूँ! आपसे मिलकर खुशी हुई\"\n",
    "    text_to_speech_stream(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b841b928-7066-4c34-b7e5-50044be18a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDczS_6wk30rFWeUasrFF7IVlocLrV2NFI\")\n",
    "\n",
    "def call_gemini_api(prompt: str) -> str:\n",
    "    \"\"\"Mock function to call ChatGPT API.\"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    print(response.text)\n",
    "\n",
    "    full_text = response.text\n",
    "    words = full_text.split()\n",
    "    trimmed_text = ' '.join(words[:20])\n",
    "    return trimmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96dd10e2-a434-4b86-88fc-feca1bdf756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मायक्रोसॉफ्ट एक बहुराष्ट्रीय तंत्रज्ञानात्मक कंपनी आहे जी संगणक सॉफ्टवेअर, ग्राहक इलेक्ट्रॉनिक्स, क्लाउड कम्प्युटिंग आणि संबंधित सेवांमध्ये विशेषज्ञता घेते. ही कंपनी 1975 मध्ये बिल गेट्स आणि पॉल अॅलन यांनी स्थापन केली होती आणि सध्या जगातील सर्वात मोठ्या आणि सर्वात मौल्यवान तंत्रज्ञानात्मक कंपन्यांपैकी एक आहे.\n",
      "\n",
      "**मायक्रोसॉफ्टचे काही प्रमुख उत्पादने आणि सेवा या आहेत:**\n",
      "\n",
      "* **ऑपरेटिंग सिस्टीम:** विंडोज, विंडोज फोन, विंडोज सर्व्हर\n",
      "* **ऑफिस उत्पादने:** मायक्रोसॉफ्ट ऑफिस, मायक्रोसॉफ्ट एक्सेल, मायक्रोसॉफ्ट वर्ड, मायक्रोसॉफ्ट पॉवरपॉइंट\n",
      "* **कलाउड कम्प्युटिंग:** मायक्रोसॉफ्ट अझ्युअर\n",
      "* **गेमिंग:** एक्सबॉक्स, एक्सबॉक्स लाइव\n",
      "* **ब्राउझर:** मायक्रोसॉफ्ट एज\n",
      "* **सर्च इंजिन:** बिंग\n",
      "* **सोशल मीडिया:** लिंक्डइन\n",
      "* **अनुप्रयोग आणि सेवा:** स्काईप, यांडेक्स\n",
      "\n",
      "**मायक्रोसॉफ्टचे महत्त्व:**\n",
      "\n",
      "* **तंत्रज्ञानाच्या क्षेत्रात आघाडीची कंपनी:** मायक्रोसॉफ्टने संगणक उद्योगात क्रांती केली आहे आणि अनेक प्रमुख तंत्रज्ञानांचे आविष्कार केले आहेत.\n",
      "* **वैश्विक उपस्थिती:** मायक्रोसॉफ्टचे उत्पादने आणि सेवा जगाच्या प्रत्येक कोपऱ्यात वापरल्या जातात.\n",
      "* **विविध क्षेत्रांवर प्रभाव:** मायक्रोसॉफ्टचे उत्पादने आणि सेवा अनेक क्षेत्रांवर प्रभाव पाडतात, त्यात शिक्षण, आरोग्यसेवा, वित्त आणि मनोरंजन यांचा समावेश आहे.\n",
      "* **मोठे गुंतवणूकदार:** मायक्रोसॉफ्ट इतर कंपन्यांमध्ये मोठ्या प्रमाणात गुंतवणूक करते आणि नवीन तंत्रज्ञानांचा विकास करते.\n",
      "\n",
      "मायक्रोसॉफ्टचे भविष्य उज्ज्वल दिसते, कारण ती कलाउड कम्प्युटिंग, कृत्रिम बुद्धिमत्ता, आणि इतर उभरत्या तंत्रज्ञानांमध्ये सक्रियपणे गुंतलेली आहे.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    prompt = \"मुझे गूगल के बारे में कुछ बताओ?\"\n",
    "    call_gemini_api(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a7481e1-f030-4da4-8700-7abc42a3c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye command recognized. Stopping...\n",
      "आप Google ईमेल के बारे में क्या जानना चाहते हैं? मुझे अधिक स्पष्टता चाहिए. उदाहरण के लिए, आप निम्न में से किसके बारे में जानकारी चाहते हैं:\n",
      "\n",
      "* **Gmail का उपयोग कैसे करें**:  आपको एक Gmail खाता कैसे बनाना है, ईमेल कैसे भेजना और प्राप्त करना है, या Gmail के अन्य सुविधाओं का उपयोग कैसे करना है।\n",
      "* **Gmail की सुविधाएँ**:  Gmail की विभिन्न सुविधाएँ जैसे स्टार, लेबल, फ़िल्टर, आदि के बारे में जानना चाहते हैं।\n",
      "* **Gmail के लिए सुरक्षा उपाय**:   अपने Gmail खाते को सुरक्षित कैसे रखें, जैसे दो-कारक प्रमाणीकरण का उपयोग करना।\n",
      "* **Gmail से जुड़े मुद्दे**:  Gmail से जुड़े किसी विशिष्ट समस्या के बारे में, जैसे कि ईमेल भेजने में परेशानी या किसी ईमेल को पुनर्प्राप्त करने में परेशानी।\n",
      "* **Gmail के अन्य पहलु**:  Gmail की अन्य विशेषताएँ जैसे Gmail से जुड़े Google Workspace या Gmail के मोबाइल ऐप के बारे में।\n",
      "\n",
      "मुझे अधिक जानकारी प्रदान करें ताकि मैं आपको सबसे अच्छी सहायता प्रदान कर सकूं।\n",
      "\n",
      "आप Google ईमेल के बारे में क्या जानना चाहते हैं? मुझे अधिक स्पष्टता चाहिए. उदाहरण के लिए, आप निम्न में\n",
      "Audio playback completed.\n"
     ]
    }
   ],
   "source": [
    "import html\n",
    "import io\n",
    "import queue\n",
    "import re\n",
    "import sys\n",
    "from google.cloud import speech, texttospeech\n",
    "import pyaudio\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "genai.configure(api_key=\"AIzaSyDczS_6wk30rFWeUasrFF7IVlocLrV2NFI\")\n",
    "\n",
    "class MicrophoneStream:\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "\n",
    "    def __init__(self: object, rate: int = RATE, chunk: int = CHUNK) -> None:\n",
    "        \"\"\"The audio -- and generator -- is guaranteed to be on the main thread.\"\"\"\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self: object) -> object:\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(\n",
    "        self: object,\n",
    "        type: object,\n",
    "        value: object,\n",
    "        traceback: object,\n",
    "    ) -> None:\n",
    "        \"\"\"Closes the stream, regardless of whether the connection was lost or not.\"\"\"\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(\n",
    "        self: object,\n",
    "        in_data: object,\n",
    "        frame_count: int,\n",
    "        time_info: object,\n",
    "        status_flags: object,\n",
    "    ) -> object:\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\n",
    "\n",
    "        Args:\n",
    "            in_data: The audio data as a bytes object\n",
    "            frame_count: The number of frames captured\n",
    "            time_info: The time information\n",
    "            status_flags: The status flags\n",
    "\n",
    "        Returns:\n",
    "            The audio data as a bytes object\n",
    "        \"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self: object) -> object:\n",
    "        \"\"\"Generates audio chunks from the stream of audio data in chunks.\n",
    "\n",
    "        Args:\n",
    "            self: The MicrophoneStream object\n",
    "\n",
    "        Returns:\n",
    "            A generator that outputs audio chunks.\n",
    "        \"\"\"\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            yield b\"\".join(data)\n",
    "\n",
    "def speechtotext(responses: object) -> str:\n",
    "    \"\"\"Iterates through server responses and returns the full transcript.\"\"\"\n",
    "    num_chars_printed = 0\n",
    "    full_transcript = \"\"\n",
    "    for response in responses:\n",
    "        if not response.results:\n",
    "            continue\n",
    "        \n",
    "        result = response.results[0]\n",
    "        if not result.alternatives:\n",
    "            continue\n",
    "        \n",
    "        transcript = result.alternatives[0].transcript\n",
    "        \n",
    "        overwrite_chars = \" \" * (num_chars_printed - len(transcript))\n",
    "        \n",
    "        if not result.is_final:\n",
    "            sys.stdout.write(transcript + overwrite_chars + \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "            num_chars_printed = len(transcript)\n",
    "        else:\n",
    "            full_transcript += transcript + \" \"\n",
    "            num_chars_printed = 0\n",
    "        \n",
    "        if re.search(r\"\\b(बस|bye|exit)\\b\", transcript, re.I):\n",
    "            print(\"Goodbye command recognized. Stopping...\")\n",
    "            return full_transcript.strip()\n",
    "    \n",
    "    return full_transcript.strip()\n",
    "\n",
    "def complete_function() -> str:\n",
    "    \"\"\"Transcribe speech from audio file.\"\"\"\n",
    "    # See http://g.co/cloud/speech/docs/languages\n",
    "    # for a list of supported languages.\n",
    "    language_code = \"hi-IN\"  # a BCP-47 language tag\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=RATE,\n",
    "        language_code=language_code,\n",
    "        model=\"command_and_search\",\n",
    "        use_enhanced=True,\n",
    "        enable_automatic_punctuation=True,\n",
    "    )\n",
    "\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content)\n",
    "            for content in audio_generator\n",
    "        )\n",
    "\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        # Get the transcribed text\n",
    "        transcribed_text = speechtotext(responses)\n",
    "        \n",
    "        if transcribed_text.strip():\n",
    "            # Here you can call your ChatGPT API function with the transcribed text\n",
    "            chatgpt_response = call_gemini_api(transcribed_text)\n",
    "            return chatgpt_response\n",
    "        else:\n",
    "            return \"No speech detected or transcribed.\"\n",
    "    return \"An error occurred during transcription.\"\n",
    "\n",
    "def call_gemini_api(prompt: str) -> str:\n",
    "    \"\"\"Mock function to call ChatGPT API.\"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    print(response.text)\n",
    "    full_text = response.text\n",
    "    words = full_text.split()\n",
    "    trimmed_text = ' '.join(words[:20])\n",
    "    return trimmed_text\n",
    "\n",
    "def text_to_speech_stream(text: str) -> None:\n",
    "    \"\"\"\n",
    "    Converts plaintext to SSML, generates synthetic audio from SSML,\n",
    "    and plays it directly through the speakers.\n",
    "\n",
    "    Args:\n",
    "    text (str): text to synthesize and play\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Replace special characters with HTML Ampersand Character Codes\n",
    "    escaped_lines = html.escape(text)\n",
    "\n",
    "    # Convert plaintext to SSML\n",
    "    ssml = \"<speak>{}</speak>\".format(\n",
    "        escaped_lines.replace(\"\\n\", '\\n<break time=\"1s\"/>')\n",
    "    )\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    # Sets the text input to be synthesized\n",
    "    synthesis_input = texttospeech.SynthesisInput(ssml=ssml)\n",
    "\n",
    "    # Builds the voice request\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"hi-IN\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n",
    "    )\n",
    "\n",
    "    # Selects the type of audio file\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.LINEAR16\n",
    "    )\n",
    "\n",
    "    # Performs the text-to-speech request\n",
    "    response = client.synthesize_speech(\n",
    "        input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    # Play the audio\n",
    "    audio_data = io.BytesIO(response.audio_content)\n",
    "    \n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=p.get_format_from_width(2),  # 16-bit\n",
    "                    channels=1,\n",
    "                    rate=24000,\n",
    "                    output=True)\n",
    "\n",
    "    chunk = 1024\n",
    "    data = audio_data.read(chunk)\n",
    "\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = audio_data.read(chunk)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    print(\"Audio playback completed.\")\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Main function to run the speech-to-text and text-to-speech pipeline.\"\"\"\n",
    "    response = complete_function()\n",
    "    print(response)\n",
    "    if response != \"No speech detected or transcribed.\" and response != \"An error occurred during transcription.\":\n",
    "        text_to_speech_stream(response)\n",
    "    else:\n",
    "        print(\"No audio detected or transcribed. Exiting...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ac416-770c-4c32-8f24-8e300e1130ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
